%\VignetteIndexEntry{primer: rawDiag}
\documentclass[nojss]{jss}
\usepackage{listings}
\usepackage[T1]{fontenc} % Use modern font encodings
\usepackage{tabularx}
\usepackage{makecell}

%\usepackage{color} 

\newcommand*\rawDiag{\textbf{\texttt{rawDiag}}}

\author{Christian Trachsel \& Tobias Kockmann \& Christian Panse}
%\title{Howto Use Diagnostic Plots for Orbitrap Instruments}
\title{\pkg{rawDiag}: an R Package for Diagnostic Plots of Mass Spectrometry Raw Data}

\Plainauthor{Christian Trachsel \& Tobias Kockmann \& Christian Panse}
\Plaintitle{Diagnostoc plots}
\Shorttitle{rawDiag}

\Keywords{proteomics, mass spectrometry}
\Plainkeywords{proteomics, mass spectrometry, visualization, method optimization}

\Abstract{

\pkg{rawDiag} is an R package which provides the user with visualizations of mass 
spectrometry data characteristics, coming from LC-MS/MS proteomics experiments. The plots implemented
in this package allow the user to check LC-MS/MS method parameters and facilitated the optimization 
thereof. The package is developed, tested and used at the Functional Genomics Center Zurich. 
The package is optimized for reading thermo fisher raw files but any other mass spectrometry 
data format is supported over the open standard mzR. \pkg{rawDiag} can be run on modern laptop 
infrastructure with sufficient speed but for larege datasets, a server infrastructure might be beneficial.  



OLD: 
\pkg{rawDiag} is an R package to do quality checks, visualizations and analysis
of mass spectrometry data, coming from proteomics experiments.
The package is developed, tested and used at the Functional Genomics Center Zurich. 
We use this package mainly for prototyping, teaching, and having {\em fun} with proteomics data.
But it can also be used to do data analysis for small scale data sets.
Nevertheless, if one is patient, it also handles large data sets.}


\newcommand*\fgcz{Functional Genomics Center Zurich\\
Swiss Federal Institute of Technology in Zurich~\texttt{|}~University of Zurich\\
Winterthurerstr. 190, CH-8057 Zurich, Switzerland}

\Address{
  Christian Trachsel \& Christian Panse\\
  \fgcz
  \\
  Telephone: +41-44-63-53912\\
  E-mail: \email{cp@fgcz.ethz.ch}\\
  URL: \url{http://www.fgcz.ch}
}

\newcommand{\rfr}{\href{http://planetorbitrap.com/rawfilereader}{RawFileReader from Thermo Fisher Scientific}~}

\begin{document}

<<echo = FALSE, eval = TRUE>>=
options(prompt = "R> ", continue = "+  ", width = 70, useFancyQuotes = FALSE)
library(tidyverse)
@

%\graphicspath{{./graphics/}}
\SweaveOpts{concordance = TRUE}
% prefix.string = graphics/primer}


\section{Introduction}
Mass spectrometry is a well-accepted and widespread method in life-sciences. 
An important task that needs to be performed prior to any data set acquisition
is the optimization of the applied mass spectrometry method.
\pkg{rawDiag} builds on the idea of the discontinued software rawMeat
(Vast Scientific). Our software allows a mass spectrometrist to analyze a raw
file in short time and delivers diagnostic plots of LC-MS/MS run chararcteristics as result. 
These visualizations are helpful for the optimization of the instrument method towards the sample at hand.

Our R package reads as input a comma-separated spreadsheet (csv) containing
LC-MS/MS run parameters. \pkg{rawDiag} is optimized to work with Thermo Fisher Scientic raw files. The
package calls a c# executable which is able generate the required csv file on the fly directly from a
raw file using the new raw file reader technology \rfr (\url{http://planetorbitrap.com/rawfilereader}).
However, any other mass spectrometry data format is also supported via the open standard mzR which requires
a conversion of the data prior to loading. A number of R helper functions reshape and subset the data and pass the desired
data-frames to ggplot2 for visualization. Trellis plots help to compare result
between different runs. Plots can be inspected interactively running the
software as an R shiny instance. Additionally, pdf reports can be generated using a customizable R
markdown file.

Processing speed of the software on modern laptop infrastructure is sufficient to provide the user with
results a few minutes after the mass spectrometry data was acquired (a single file containing $\approx 80'000$ individual
spectra is processed in less than 50 sec). For the analysis of larger data sets, 
computing on a server deployed installation is recommended.

All necessary steps can be done with the R command line or by using the shiny
application on any modern computer.
 
The diagnostic visualization are peptide ID free and rely on data logged by the instrument directly in the
raw data file. This makes the software slim and fast and does not require an full additional data analysis
pipeline.


\section{Installation}


The R package can be installed via the following command line:
<<eval=FALSE>>=
library(devtools)
devtools::install_github("fgcz/rawDiag")
@

A docker recipe for compiling the adapter function implemented in
\proglang{C\#} using the \rfr is contained in the R package and listed below.

\lstdefinelanguage{docker-compose-2}{
  keywords={version, volumes, services},
  keywordstyle=\color{blue}\bfseries,
  keywords=[2]{image, environment, ports, container_name, ports, links, build},
  keywordstyle=[2]\color{olive}\bfseries,
  identifierstyle=\color{black},
  sensitive=false,
  comment=[l]{\#},
  commentstyle=\color{blue}\ttfamily,
  stringstyle=\color{red}\ttfamily,
  morestring=[b]',
  morestring=[b]"
}

\IfFileExists{../inst/docker/Dockerfile}{
  \lstinputlisting[language=docker-compose-2,
  caption={Dokerfile for compiling the ThermoFisher rawfilereader adapter code.},
  breaklines=false,
  label={code:compose}]{../inst/docker/Dockerfile}
}{

NO DOCKERFILE

}

The docker image is built and executed by using the follwoing command line.
\begin{lstlisting}[language=bash]
docker build -t rawfilereader .

docker run -v /scratch:/scratch \
  -a stdin -a stdout -i -t rawfilereader bash
\end{lstlisting}


\section{Getting started} 

attach the package
<<>>=
library(rawDiag)
@

look into for documentation

<<eval=FALSE>>=
help(package="rawDiag")
@

\section{Read Data}

\subsection{Using The New Raw File Reader}

The function \code{read.raw} uses the \rfr to 
extract the following information out of the mass spectrometric meassurement.

<<>>=
library(rawDiag)
rawDiag:::.getDesiredColNames()
@

We use R for the implementation and read the data using the pipe command as it
can be seen in the following code snippet:

<<eval = FALSE>>=
system.time(RAW <- read.raw(file = "~/data/20130115_01_iRT_Fet10fmol.RAW"))
@

\subsection{Using the mzR package}

<<eval = FALSE>>=
library(mzR); 
library(rawDiag)
RAW <- rawDiag:::as.rawDiag.mzR(openMSfile("/scratch/cpanse/PXD006932/Exp3A/20161213_NGHF_DBJ_SA_Exp3A_HeLa_1ug_15min_15000_01.mzML"))

PlotChargeState(RAW)
PlotCycleLoad(RAW)
PlotCycleTime(RAW)
# PlotInjectionTime(RAW)
# PlotLockMassCorrection(RAW)
PlotMassDistribution(RAW)
PlotPrecursorHeatmap(RAW)
PlotMzDistribution(RAW)
PlotPrecursorHeatmap(RAW)
PlotScanFrequency(RAW)
PlotScanTime(RAW)
PlotTicBasepeak(RAW)
@



\section{Usage}


In the following section we demonstrate how the software can be used for the optimization of an
LC-MS/MS method. For this we first load the demonstration data shipped with the package.

load sample data:
<<label=load, eval=TRUE>>=
load(file.path(path.package(package = "rawDiag"),
                 file.path("extdata", "WU163763.RData")))
stopifnot(is.rawDiag(WU163763))
@

This data was recorded to investigate the optimal number of MS2 scans between two consecutive MS1 scans on a
Q-Exactive HF-X mass spectrometer injecting a commercial HeLa digest. Since the data was recorded in triplicate 
per used method, we will have overplotting issues. Therefore we first filter the data for a single injection
per method.

<<label=filter, eval=TRUE>>=
  library(tidyverse)
df <- dplyr::filter(WU163763, filename == "20180220_04_S174020_Pierce_HeLa_Protein_Digest_Std.raw" |
                      filename == "20180220_05_S174020_Pierce_HeLa_Protein_Digest_Std.raw" |
                      filename == "20180220_09_S174020_Pierce_HeLa_Protein_Digest_Std.raw")
@

Now to the actual walk through. Assuming we have a starting method we want to optimize. This method is 
performing 18 MS2 scans for each MS1 scan. With the given transient lenght from the used instrument we can calculate
the cycle time (time required to scan one MS1 and 18 MS2 scans). In our case we find the cycle time to be
$\approx$ 0.6 second. For a 120 min chromatography with expected peak width of 20-30 seconds, this would result in
30-50 MS1 points per peak. In other words the instrument would spend too much time recording MS1 compared 
to MS2. Therefore we addapted the methods to perform 36 and 72 MS2 scans respectively. With these two new methods
we recorded the the data and we can now analyse the results with the dignostic plots of this package.

First parameter we want to check is the TIC or base peak. With this plot we can see if the data was recorded
properly and if the signal response of the sample is the same over the three injections.


<<label=TIC, fig = TRUE, echo=TRUE, include=TRUE, warnings=TRUE>>=
print(gp <- PlotTicBasepeak(df, method = "overlay"))
@

signal response and chromatography is ok for the three injections. As next point we want to check the actuall cycle time
of the injections. Please note we also make use of the grammar of graphics implementation of ggplot2 by modifiying the plot appearance on the fly. Here we change the standard plot legend from the right side of each plot to the top for better readabillity. This is done by adding the additional facet\_wrap statement after the initial call of the plot function.

<<label=Time, fig = TRUE, echo=TRUE, include=TRUE, warnings=TRUE>>=
print(gp <- PlotCycleTime(df, method = "trellis") +
  facet_wrap(~ filename, ncol =1))
@
 
We can see the the cycle time for the top 18 method (file 09) is arround 0.6 seconds during the elution phase of the peptides.
The red dashed line indicates the calculated cycle time. As already mentioned, with this method we produce too many MS1 data points. The cycle time of the top 36 and top 72 methods respectively have cycle times of 1.1 second and 2 seconds respectively. With the used chromatography we produce $\approx$20-30 MS1 point for the top 36 and $\approx$10-15 MS1 points for the top 72 method. This is a much better value compared to the initial method.
The next thing to check is if the instrument is actually using the available MS2 capacity. For this we plot the cycle load (the actually performed MS2 scans for each MS1 scan).

This is done by adding the additional "facet\_wrap()" statement after the initial call of the plot function.

<<label=Load, fig = TRUE, echo=TRUE, include=TRUE, warnings=TRUE>>=
print(gp <- PlotCycleLoad(df, method = "trellis"))
@

From the plot we can see that all mehtods actually use the available number of MS2 scans during the main peptide elution phase. The blue line is representing the trend as a fitted gam model.

The parameter to be optimized for this walk through is the "top-N" spacing (number of MS2 scans between 
to MS1 scans).
  
adapt y-axis number of tickmarks

<<label=cycletime, fig = TRUE, width=4.5, height=6, echo=TRUE, include=TRUE, warnings=TRUE>>=
  library(ggplot2)
print(gp <- PlotCycleTime(WU163763) + 
        scale_y_continuous(breaks = scales::pretty_breaks(3)))
@
  
print object class

<<>>=
  class(gp)
@
  
  
Next, we discover the unexpected mass spec ???
and
apply subsetting

<<label=scantime, fig = TRUE, width=4.5, height=4, echo=TRUE, include=TRUE>>=
# library(dplyr)
gp <- WU163763 %>% 
  filter(filename == "20180220_04_S174020_Pierce_HeLa_Protein_Digest_Std.raw") %>% 
  PlotScanTime() 

print(gp + 
        facet_grid(filename + MassAnalyzer + MSOrder ~ .))
@
  


\section{Benchmark}

We performed a benchmark using the following command on a  
Intel(R) Xeon(R) CPU E5-2698 v3 @ 2.30GHz system having
64 processors and running Debian 8.
We read 517533 scans information from eight raw files using the adapter function \code{read.raw}.

<<eval = FALSE>>= 
#R
library(parallel)

f <- list.files()
f <- f[grep("raw$", f)]

b <- lapply(1, function(x){.benchmark(f, exe="~/RiderProjects/fgcz-raw/bin/Debug/fgcz_raw.exe")})

b <- plyr::rbind.fill(lapply(b, plyr::rbind.fill))

b$overall.runtime <- as.integer(format(b$end.time, "%s")) - 
  as.integer(format(b$start.time, "%s"))

b$system <- "Linux"
b.Linux <- b
save(b.Linux, file='benchmark.RData')
@
  
Here, five times a set
of eight raw files were read into the R environment 
using between one singe and eight CPUs in parallel.

The boxplot below displays the result.

<<label=benchmark-time, eval = TRUE, fig = TRUE, width = 4, height =4, echo = FALSE, include = FALSE>>=
rawDiag:::.technote_benchmark_figure_1() 
@
<<label=benchmark-throuput, eval = TRUE, fig = TRUE, width = 4, height = 4, echo = FALSE, include = FALSE>>=
rawDiag:::.technote_benchmark_figure_2()
@

\begin{figure}
\includegraphics[width=0.49\columnwidth]{primer-benchmark-time}
\includegraphics[width=0.49\columnwidth]{primer-benchmark-throuput}

\caption{Benchmark -- The left plot shows the overall logarithmic 
scaled runtime of 128 raw files.  The graphic on the right side shows 
the thereof derived IO throughput as scan information per second. The 
plots illustrate that both systems, server, and laptop, can analyze 
95GB of instrument data within less than three minutes.
}
 
\label{figure:benchmark}
\end{figure}

\section{Session information}
An overview of the package versions used to produce this document are shown below.


<<sessioninfo, results=tex, echo=FALSE>>=
toLatex(sessionInfo())
@

\nocite{*}

\bibliography{rawDiag}


\end{document}
