%\VignetteIndexEntry{JPR pr-2018-001736}
\documentclass[journal=jprobs,manuscript=article]{achemso}
\setkeys{acs}{articletitle=true}
\setkeys{acs}{doi = true}
\SectionNumbersOn

\usepackage[T1]{fontenc} % Use modern font encodings
\usepackage[colorlinks = true,
            linkcolor = blue,
            urlcolor  = blue,
            citecolor = blue,
            anchorcolor = blue]{hyperref}


\usepackage{chemformula} % Formula subscripts using \ch{}
\usepackage[T1]{fontenc} % Use modern font encodings
\usepackage{tabularx}
\usepackage{makecell}


\newcommand*\mycommand[1]{\texttt{\emph{#1}}}
\newcommand*\code[1]{\texttt{\emph{#1}}}

\newcommand{\doi}[1]{\href{http://dx.doi.org/#1}{\nolinkurl{#1}}}
\newcommand*\rawDiag{\textbf{\texttt{rawDiag}}}

\newcommand*\fgcz{$\ast$~correspondence, 1. Functional Genomics Center Zurich\\ Swiss Federal Institute of Technology Zurich~\texttt{|}~
University of Zurich\\Winterthurerstr. 190, CH-8057 Zurich, SWITZERLAND}

\author{Christian Trachsel$^1$}
\affiliation{\fgcz}
\email{christian.trachsel@fgcz.ethz.ch}
\phone{+41 44 63 53910}

\author{Christian Panse$^1$}
\affiliation{\fgcz}

\author{Tobias Kockmann$^1$}
\affiliation{\fgcz}

\author{Witold E. Wolski$^1$}
\affiliation{\fgcz}

\author{Jonas Grossmann$^1$}
\affiliation{\fgcz}

\author{Ralph Schlapbach$^1$}
\affiliation{\fgcz}


\title[\rawDiag]
  {\rawDiag~--~an R package supporting rational LC-MS method optimization for bottom-up proteomics}


\abbreviations{IR,NMR,UV}

\keywords{mass-spectrometry, R-package, multi-platform,
method-optimization, reproducible research, quality-control,
visualization}

\begin{document}

<<echo = FALSE, eval = TRUE>>=
options(prompt = "R> ", continue = "+  ", width = 70, useFancyQuotes = FALSE)
library(tidyverse)
library(rawDiag)
dir.create('graphics')
stopifnot(packageVersion('rawDiag') >= '0.0.1')
@

\graphicspath{{./graphics/}}
\SweaveOpts{concordance = TRUE, prefix.string = graphics/rawDiag}
\begin{tocentry}

\includegraphics[height=3.5cm,keepaspectratio]{39515832-84b561ea-4dfb-11e8-9411-276bc6fb71d6}

\end{tocentry}

\begin{abstract}
Optimizing methods for liquid chromatography coupled to mass spectrometry (LC-MS) is a non-trivial task. Here we present \rawDiag, a software tool supporting rational method optimization by providing MS operator-tailored diagnostic plots of scan level metadata.
\rawDiag~is implemented as an R package and can be executed on the R command line, or through a graphical user interface (GUI) for less experienced users. The code runs platform independent and can process a hundred raw files in less than three minutes on current consumer hardware, as we show in our benchmark. In order to demonstrate the functionality of our package we included a real-world example taken from our daily core facility business.
\end{abstract}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
Over the last decade, liquid chromatography coupled to mass 
spectrometry (LC-MS) has evolved into the method of choice in the 
field of proteomics \cite{Cox2011, Yates2009, Nesvizhskii2007,
Mallick2010, Bensimon2012}. During a typical bottom up LC-MS 
measurement, a complex mixture of analytes is separated by a liquid 
chromatography system that is connected to a mass spectrometer (MS) through 
an ion source interface. The analytes which elute from the chromatography system  over time are 
converted into a beam of ions in this interface and the MS records from this ion 
beam a series of mass spectra containing detailed information on the 
analyzed sample \cite{Savaryn2016, Matthiesen2013}. As raw data are considered the mass spectra and their metadata, usually recorded in a vendor specific binary format. During a 
measurement, the mass spectrometer applies internal heuristics which enables the instrument to 
adapt to sample properties (sample complexity, amount of ions, etc.) in near real time. Still, method 
parameters controlling these heuristics need to be set prior to the 
measurement. For an optimal measurement result, a carefully balanced 
set of parameters is required, but their complex interactions with each other make LC-MS method 
optimization a challenging task.

Here we present \rawDiag, a platform independent software tool 
implemented in R that supports LC-MS operators during the process of 
empirical method optimization. Our work builds on the ideas of the 
discontinued software ``rawMeat'' (vastScientific). Our application is currently 
tailored towards spectral data acquired on Thermo Fisher Scientific 
instruments (raw format), with a special focus on Orbitrap mass 
analysers (Exactive or Fusion instruments). These instruments are 
heavily used in the field of bottom-up proteomics in order to analyse 
complex peptide mixtures derived from enzymatic digests of 
proteomes.\\
\rawDiag~is meant to run post MS acquisition,  
optimally as interactive R shiny application and produces a series of diagnostic 
plots visualizing the impact of method parameter choices on the acquired data 
across injections. If static reports are required, pdf files can be 
generated using R markdown. The visualizations generated by 
\rawDiag~can be used in an iterative method optimization process (see 
Figure~\ref{figure:arch}) where an initial method is tested, analyzed 
and based on these results a hypothesis can be formulated to optimize 
the method parameters. The same sample is then re-analyzed with the optimized 
method and the data can enter the refinement loop again until the operator is 
satisfied with the found set of method parameters for the sample under investigation.

In this manuscript we 
present the architecture and implementation of our tool. We provide example plots,
show how plots can be redesigned to meet different requirements and discuss the application based on a use 
case.

\begin{figure}
 \includegraphics[width=1.0\columnwidth]{rawDiagR2}
\caption{
\rawDiag~R package architecture.
(1)~ LC-MS scan files in vendor-specific binary format.
(2)~\rawDiag~reads scan metadata through vendor library (magenta = Thermo Fisher Scientific RawFileReader), or by conversion to PSI formats using msConvert (blue = mzML).
(3)~Utility function coerces scan metadata from different sources to common format.
(4)~Central data structure used for visualization/modeling: tidy data frame~\cite{Wickham2014} in wide format (rows: scans, columns: scan attributes)
(5)~The R-package provides a variety of functions to visualize mass
spectrum-related metadata (see Table 1 for details).
(6)~Typical R command line usage for experienced R users.
(7)~Reporting functionality is provided through R markdown.
(8)~Interactive GUI-driven exploration is possible through the R shiny package.
}
\label{figure:arch}
\end{figure}


\section{Experimental Procedures}

\subsection{Architecture}

The layered design of \rawDiag~is one of its architectural key features.
The input layer allows fast reading of massive data by directly applying the vendor libraries, e.g., for Thermo Fisher Scientific raw files \cite{RawFileReader}.
The processing layer provides auxiliary functionalities such as selecting, filtering and aggregation.
The plotting functions implemented in the processing layer provide the most frequently used visualizations in the MS field. The design of these plots based on the Grammar of Graphics \cite{Wilkinson2005} allow quick and easy redesign of them if needed.
Being implemented as R package\cite{R} it provides support for R
command line, interactivity through R shiny and pdf report generation
using R markdown. Figure~\ref{figure:arch} graphs a schematic overview of the architecture.

\subsection{Implementation}

The entire software is implemented as an R package providing a full 
documentation and includes example data. All diagnostic plots are 
generated by R~\cite{R} functions using the ggplot2 \cite{Hadley2009} graphical 
system, based on ``The Grammar of Graphics'' \cite{Wilkinson2005}. The 
package ships with an adapter function \code{read.raw} which returns 
an R \code{data.frame} object \cite{Wickham2014} from the raw data input file. In its current 
implementation, the adapter function \code{read.raw} is used for directly
reading Thermo Fisher Scientific raw files,
using a \texttt{C\#} programmed executable,
based on the platform-independent New RawFileReader .Net 
assembly\cite{RawFileReader}. 
A Docker recipe for the entire build process of the \texttt{C\#}
based executable ships with the R package.
Additionally, the open file standards  
can be loaded into the R environment using the R package \textbf{\texttt{mzR}}~\cite{mzR, msdata} in combination with 
the S3 adapter function \code{as.rawDiag.mzR}. We thereby provide support for vendor file formats which 
do not have a native reading function so far.

Since in general more than one MS file is loaded and visualized, the adapter function 
supports multiprocessor infrastructure through the \textbf{\texttt{parallel}} R package.
In order to be flexible with the entire variety of 
instruments we implemented the two utility functions 
\code{is.rawDiag} and \code{as.rawDiag}. While the 
\code{is.rawDiag} function checks if the input object 
fulfills the requirements of the package's diagnostic plot functions, 
the \code{as.rawDiag} method coerce the object into the required data strucuture if needed.

\subsection{Evaluation}

<<label=benchmark-time, eval = TRUE, fig = TRUE, width = 6, height =6, echo = FALSE, include = FALSE>>=
rawDiag:::.technote_benchmark_figure_1() 
@
<<label=benchmark-throuput, eval = TRUE, fig = TRUE, width = 6, height = 6, echo = FALSE, include = FALSE>>=
rawDiag:::.technote_benchmark_figure_2()
@

<<benchmark, echo=FALSE>>=
data(benchmark)
  
b.Linux$IO.throuput <- sum(unique(b.Linux$nrow)) / b.Linux$overall.runtime 
@

We performed a benchmark of our R package with a large data set on two different compute systems. The performance is defined as the number of spectra information which the software can extract from the raw file and load into an R session per second. This information throughput benchmark was performed as a function of the used processes. The two compute systems used were a Linux server and an Apple MacBock Pro. Their detailed hardware specifications are listed 
in Table~\ref{table:specs}.

\begin{table}
\centering
%\resizebox{0.9\columnwidth}{!}{
\begin{tabularx}{\textwidth}{l|X|X}
\hline
\hline
System parameters & Linux Server  & Apple MacBook Pro 2017\\
\hline
number of cores & 64  & 8\\
CPU & Intel(R) Xeon(R) CPU E5-2698 v3 @ 2.30GHz & 2.9GHz Intel Core i7\\
disk  & RAID Module RMS25CB080  & SSD SM1024L\\
filesystem  &   XFS & APFS\\
\hline
OS  & SMP Debian {3.16.43-2+deb8u2} &  Darwin Kernel Version 17.4.0\\
Mono JIT compiler version& 5.8.0.127& 5.2.0.224\\
\hline
R&3.4.3&3.4.2\\
mzR & 2.8.1&\\
ThermoRawFileReader&4.0.22&4.0.22\\
\hline
\hline
\end{tabularx}


\caption{\label{table:specs}Summary of the hardware specifications.}
\end{table}

As benchmark data, we downloaded the raw files described in 
\cite{pmid29183128} and available through 
\href{http://proteomecentral.proteomexchange.org/cgi/GetDataset?ID=PXD006932}{proteomeXchange PXD006932} on our filesystem. 
For the benchmark we limited the input to \Sexpr{length(unique(b.Linux$nrow))} files, 
corresponding to two times the available number of processor cores of 
the Linux system. The data has an overall file size of 
\Sexpr{round(sum(unique(b.Linux$file.size)) / 1024^3)} GB and 
contains \Sexpr{format(sum(unique(b.Linux$nrow)), scientific=FALSE, big.mark = "'")}
individual mass spectra in total.
For performance evaluation of to the open file standard implementation\cite{mzR}, 
we converted the raw files into mzML files using ProteoWizard version 3.0.11252
64-bit on Windows 10. 
The benchmark was performed starting with the highest amount of cores in order to avoid caching issues. The number of available CPUs was successively reduced. For each number of processes, the data extraction was run fife times.
The results of this benchmark are visualized in Figure~\ref{figure:benchmark}.

%The best performance on our system is achieved by using
%\Sexpr{min(b.Linux$ncpu [b.Linux$IO.throuput == max(b.Linux$IO.throuput)])}
%CPUs having an performance of reading
%\Sexpr{format(round(max(b.Linux$IO.throuput)), scientific = FALSE, big.mark = "'")} scan informations per second.

%\begin{figure}

%\includegraphics[width=0.49\columnwidth]{rawDiag-benchmark-time}
%\includegraphics[width=0.49\columnwidth]{rawDiag-benchmark-throuput}

%\caption{Benchmark -- The left plot shows the overall logarithmic 
%scaled runtime of 128 raw files. The graphic on the right side shows 
%the derived IO throughput thereof as scan information per second. The 
%plots illustrate that both systems, server and laptop, can analyze 
%95GB of instrument data within less than three minutes when reading directly from the raw files. The performance evaluation of the open standard input was only possible on the server system due to processor overheating on the laptop. 
%}
 
%\label{figure:benchmark}
%\end{figure}

\subsection{Visualization}

This package is providing several plot functions tailored 
towards MS data. A list of the implemented 
plot functions with a short description 
can be found in Table~\ref{table:functions}.
An inherent problem of visualizing 
data is the fact that depending on the data at hand certain 
visualizations lose their usefulness (e.g. overplotting in scatter 
plot if too many data points are present). To address this 
problem, we implemented most of the plot functions in different 
versions inspired by the work of Cleveland\cite{Cleveland93}, Sarkar\cite{RSarkar2008} and Wickham\cite{Wickham2014,Hadley2009}. The 
data can be displayed in trellis plot manner using the faceting 
functionality of ggplot2 (see Figure~\ref{figure:viz}A). Alternatively,
overplotting using color coding (Figure~\ref{figure:viz}B) or violin plots based on 
descriptive statistics values (Figure~\ref{figure:viz}C) can 
be chosen. This allows the user to interactively change the appearance 
of the plots based on the situation at hand (e.g. a large number of 
files are best visualized by violin plots giving the user an idea 
about the distribution of the data points). Based on this a smaller 
subset of files can be selected and visualized with another technique. \\
To benefit from the grammar of graphics (changing individual plot layers e.g., adapt y-axis scaling, change axis labels, 
add title or subtitles) each of the implemented plot functions always returns 
the \code{ggplot} object. Due to the implementation of this design 
pattern those \code{ggplot} objects can be further altered by adding new 
layers, allowing a customization of the plots if needed. 
The following R code snippet produces the three plots shown in Figure~\ref{figure:viz} 
and demonstrates the described feature of modifying an existing \code{ggplot} object
by eliminating the legend in the last two plots.

<<label=color, echo = FALSE>>=
color.vector <- c("#08306B", #"#6BAED6",
                  "#2171B5",
                  "#6BAED6", #"#08306B",
                  "#00441B", #"#74C476",
                  "#238B45",
                  "#74C476", #"#00441B",
                  "#7F2704", #"#3F007D",
                  "#D94801", #"#6A51A3",
                  "#FD8D3C")

color.vector.2 <- c("#08306B", #"#6BAED6",
                    "#6BAED6", #"#08306B",
                    "#00441B", #"#74C476",
                    "#74C476", #"#00441B",
                    "#7F2704") #"#3F007D",

@

<<label=codeSnippet, eval = TRUE, fig = TRUE, eval=FALSE>>=
library(rawDiag)
data(WU163763)
PlotMassDistribution(WU163763)
PlotMassDistribution(WU163763, method = 'overlay') +
  theme(legend.position = 'none')
PlotMassDistribution(WU163763, method = 'violin') +
  theme(legend.position = 'none')
@

<<label=visualization_trellis, eval = TRUE, fig = TRUE, width = 16, height = 6, echo = FALSE, include = FALSE>>=
rawDiag:::.technote_viz_figure_1(WU163763) 
@
<<label=visualization_overlay, eval = TRUE, fig = TRUE, width = 8, height = 4, echo = FALSE, include = FALSE>>=
rawDiag:::.technote_viz_figure_2(WU163763) +
  theme(legend.position = 'none')
@
<<label=visualization_violin, eval = TRUE, fig = TRUE, width = 8, height = 4, echo = FALSE, include = FALSE>>=
rawDiag:::.technote_viz_figure_3(WU163763) +
  theme(legend.position = 'none')
@

Interactive visualization is achieved by embedding 
the plot functions into a R shiny application. Static versions of 
the plots can be easily generated by the provided R markdown file that 
allows the generation of pdf reports.

Protein and peptide identification results required for certain Figures in this mansucript were generated by Proteome~Discoverer version 2.2 using the following search settings: Data was searched against the human Uniprot reference proteome using SEQUEST HT 
(tryptic enzyme specificity including 2 missed cleavages, precursor mass tolerance: 20 ppm, fragment mass tolerance: 0.5 Da, Carbamidomethyl as static modification, Dynamic Modifications: Methionine oxidation, N-terminal protein acetylation). Resulting identifications were filtered to 1\% peptide FDR using Percolator.


\begin{figure}[ht]
\includegraphics[width=0.98\columnwidth,keepaspectratio]{rawDiag-visualization_trellis}
\includegraphics[width=0.49\columnwidth,keepaspectratio]{rawDiag-visualization_overlay}
\includegraphics[width=0.49\columnwidth,keepaspectratio]{rawDiag-visualization_violin}

\caption{Concurrent metadata visualization applying \code{PlotMassDistribution} to nine raw files acquired in DDA mode (sample was 1$\mu$g HeLa digest.) \textbf{A)} method trellis; the mass distribution is plotted as a histogram and the color code represents the charge states the precursors \textbf{B)} method overlay; the mass distribution is graphed as a density function and the color code represents the different raw files. \textbf{C)} method violin; the mass distribution is displayed as a violin plot and the colors indicate the different raw files.}

%facet plot of the mass distribution in relation to the precursor charge from nine raw files. \textbf{B)} Overlay representation of the same mass distributions as density plot but without the charge state information. \textbf{C)} Descriptive plot where the mass distribution is displayed as violin grouped by the charge state for the same nine raw files.}
\label{figure:viz}
\end{figure}

<<overview, echo=FALSE>>=
data(WU163763)
WU <- WU163763[WU163763$filename %in% unique(WU163763$filename)[1:2], ]
rv <- rawDiag:::PlotAll(WU, prefix="graphics/rawDiag")
@

\newcommand{\G}[1]{
\IfFileExists{graphics/rawDiag-#1.png}{\parbox[c]{1.5cm}{\includegraphics[width=1.5cm, height=1.5cm]{graphics/rawDiag-#1}}}{-}
}


\begin{table}
\centering
\begin{scriptsize}
%\resizebox{0.9\columnwidth}{!}{
\begin{tabularx}{\textwidth}{lcccX}
\hline
\hline
function name  & trellis & overlay & violin & description\\
\hline
\code{PlotChargeState}    &\G{PlotChargeState-trellis}       &\G{PlotChargeState-overlay}       &        -                         & displays charge state distributions as biologist-friendly bar charts as absolute counts.\cite{pmid24645190}\\
\code{PlotCycleLoad}         &\G{PlotCycleLoad-trellis}   &\G{PlotCycleLoad-overlay}   &\G{PlotCycleLoad-violin}& displays duty cycle load (number of MS2 scans per duty cycle) as a function of retention time (RT) (scatter plots) or its marginal distribution (violin).\\
\code{PlotCycleTime}         &\G{PlotCycleTime-trellis}         &\G{PlotCycleTime-overlay}         &\G{PlotCycleTime-violin}        & displays cycle time with respect to RT (scatter plots) or its marginal distribution (violin). A smooth curve graphs the trend. The maximum is indicated by a red dashed line.\\
\code{PlotInjectionTime}     &\G{PlotInjectionTime-trellis}&\G{PlotInjectionTime-overlay}     &\G{PlotInjectionTime-violin}           & displays injection time as a function  of RT. A smooth curve graphs the trend. The maximum is indicated by a red dashed line.\\
\code{PlotLockMassCorrection}      &\G{PlotLockMassCorrection-trellis}      &\G{PlotLockMassCorrection-overlay}      &\G{PlotLockMassCorrection-violin}     & graphs the lock mass deviations along RT (note: this example data were acquired with lock mass correction).\\
\code{PlotMassDistribution}  &\G{PlotMassDistribution-trellis}  &\G{PlotMassDistribution-overlay}  &\G{PlotMassDistribution-violin} & displays mass distribution using color coding according to charge state (trellis) or file (overlay, violin).\\
\code{PlotMassHeatmap}       &\G{PlotMassHeatmap-trellis}                    & \G{PlotMassHeatmap-overlay}                                   & -                                 & draws a computer scientist-friendly hexagon binned heatmap of the peak count charge deconvoluted mass along RT.\\
\code{PlotMzDistribution}    &\G{PlotMzDistribution-trellis}&\G{PlotMzDistribution-overlay}& \G{PlotMzDistribution-violin}& a scatter plot of m/z versus RT on MS1 level (no density; with overplotting.). violin display the marginal m/z distribution of each file.\\
\code{PlotPrecursorHeatmap}  &\G{PlotPrecursorHeatmap-trellis}            & \G{PlotPrecursorHeatmap-overlay}                                   & -                                 & according to \code{PlotMassHeatmap}  but displaying convoluted data.\\
\code{PlotScanFrequency}     &\G{PlotScanFrequency-trellis}     &\G{PlotScanFrequency-overlay}     &\G{PlotScanFrequency-violin}    & graphs scan frequency versus RT or scan frequency marginal distribution for violin.\\
\code{PlotScanTime}         &\G{PlotScanTime-trellis}          &\G{PlotScanTime-overlay}          &\G{PlotScanTime-violin}         & plots scan time as function of RT for each MSn level. A smooth curve displays the trend.\\
\code{PlotTicBasepeak}      &\G{PlotTicBasepeak-trellis}       &\G{PlotTicBasepeak-overlay}       &\G{PlotTicBasepeak-violin}      & displays the total ion  chromatogram (TIC) and the base peak chromatogram.\\
\hline
\hline
\end{tabularx}
\end{scriptsize}
\caption{
The \rawDiag~cheatsheet lists the functions of the package using a subset of the provided  `WU163763` dataset.
Each thumbnail gives an impression of the plot function's result. 
The column names `trellis,' `overlay' and `violin'  were given as method attribute.
Marginal distribution plots for discrete response variables are not supported.
}
\label{table:functions}
\end{table}


\section{Results and discussion}

Our application \rawDiag~acts as an interface to file reader 
libraries from MS vendors. These libraries are able to 
access the scan data, as well as the scan metadata stored in the 
proprietary file formats. In its current configuration, \rawDiag~is 
able to read data from Thermo Fischer Scientific raw files via a 
\texttt{C\#} executable. This executable is extracting the information 
stored in the raw file via the platform-independent RawFileReader .Net 
assembly. To avoid writing to the disk, the information is directly fed into an R 
session using the \code{pipe} command. The data integrity is checked by the 
\code{is.rawDiag} function and coerced by the \code{as.rawDiag} function into the
proper format for the plot functions, if required. 

\begin{figure}

\includegraphics[width=0.45\columnwidth]{rawDiag-benchmark-time}
\includegraphics[width=0.45\columnwidth]{rawDiag-benchmark-throuput}

\caption{Benchmark -- Panel A shows the overall logarithmic 
scaled runtime required to process 128 raw files. The magenta curve displays the runtime in dependancy of the number of used CPUs when reading directly from the raw files and the blue curve indicates the performance when reading from mzML files. Panel B depticts the corresponding IO throughput in scans extracted per second. Again the CPU dependent throughput for processing raw files is shown in magenta and the throughput for reading mzML files is given in blue.
The plots illustrate that both systems, server and laptop, can analyze 
95GB of instrument data within less than three minutes when reading directly from the raw files. The performance evaluation of the open standard input was only possible on the server system due to processor overheating on the laptop. 
}
 
\label{figure:benchmark}
\end{figure}

The idea of the package is to provide the user with diagnostic plots a short time after the MS raw data is acquired. 
To test if our software is fast enough for this task, we performed a benchmark analysis. In panel A of
Figure~\ref{figure:benchmark} the overall runtime dependancy of the number of used CPUs is depicted. We derived the processing frequency as spectra loaded per second and the corresponding graph is shown in panel B of Figure~\ref{figure:benchmark}. The processing speed on both tested systems is fast when directly reading from the raw file. The performance drops by at least an order of magnitude when using the mzML files as input. Additionally, for this test we only have data, since the processing on the MacBook needed to be stoped due to processor overheating problems. Nevertheless, for processing only small amount of files (the usual case during method optimization), the processing speed of both systems, reading from both file formats is fast enough to provide the diagnostic visualizations in short time. A single file containing $\approx 80'000$ individual
spectra is processed in less than 50 sec.

As soon as the data is 
extracted and loaded into the R session, the different plot functions (see Table~\ref{table:functions})
can be called upon the data for the visualizations of LC-MS run 
characteristics. The generated diagnostic plots help the MS operator to draw conclusions about the choosen MS method parameters on a rational base. Base on these conclusions, a hypothesis for the method optimizations can be formulated and data from the optimized methods can be visualized in order to check if the method adaptation led into the right direction. A use case example
of this process will be discussed in the following paragraph. In order to be flexible towards
different situations where a single visualization technique might lose its usability,
most plot functions can be called in three different versions. This allows to circumvent
overplotting issues or helps to detect trends when multiple files are loaded. A list of the currently 
implemented plot functions can be found in Table~\ref{table:functions} and the flexibility of choosing different 
visualization styles is depicted in Figure~\ref{figure:viz}. 
In the interactive mode, the application runs as an R shiny server 
and generates the same plots as in the command line usage but does not require profound R knowledge from the user. All implemented plots can be inspected in different tabs in the shiny instance and radio buttons allow to switch between the different plot styles. The size of the plots can easily be adjusted to the screen by a slider and and additional table is generated, summarizing all the loaded data for an overview at a single glance.

\subsection{Use case example}
\label{section:application} 
Starting from an initial method template described by Kelstrup et al.,\cite{pmid29183128} 
we analyzed 1 $\mu$g of a commercial tryptic HeLa digest on a Q-Exactive HF-X 
instrument using classical shotgun heuristics. Subsequently, the 
resulting raw data was mined using \rawDiag. Inspection of the 
cycle time plot (not shown) suggested that analysis time was not optimally 
distributed between the different scan levels (precursor and fragment 
ions) under the applied chromatographic conditions. To test this hypothesis, we ramped the parameter 
controlling the number of dependent scans per instrument cycle (TopN), in two 
steps and applied the resulting methods by analyzing the same material 
in technical triplicates. Visualization applying \rawDiag~confirmed 
that all three methods exploit the maximum number of dependent scans (18, 
36 and 72) during the separation phase of the gradient (see Figure~\ref{figure:application}B). Concurrently, 
the MS2 scan speed increased from $\approx$30 to $\approx$36 and $\approx$40 Hz, respectively
(see Figure~\ref{figure:application}A). Using the modified methods, the instrument is spending 5 and 10 min more time on MS2 
scans during the main peptide elution phase, comparing the methods to the initial "Top18" method (see Figure~\ref{figure:application}E). 
These optimized methods not only showed better run characteristics but
ultimately also resulted in more peptide and protein 
identifications, as shown in Figure~\ref{figure:application}C and \ref{figure:application}D. For database searches, Proteome~Discoverer with search settings described in the experimental procedures section. 


<<label=usecase1_data, echo=FALSE>>=
library(tidyverse)
data(WU163763)

load(file.path(path.package(package = "rawDiag"),
               file.path("extdata", "WU163763_PD.RData")))

searchResults <- WU163763_PD

color.vector <- c("#08306B", #"#6BAED6",
                  "#2171B5",
                  "#6BAED6", #"#08306B",
                  "#00441B", #"#74C476",
                  "#238B45",
                  "#74C476", #"#00441B",
                  "#7F2704", #"#3F007D",
                  "#D94801", #"#6A51A3",
                  "#FD8D3C") #"#9E9AC8")

DescValues <- searchResults %>% 
  group_by(TopN) %>% 
  summarise_at(vars(proteins, peptides, psm), funs(mean(.), sd(.))) %>% 
  mutate_at(vars("proteins_mean","peptides_mean", "psm_mean","proteins_sd","peptides_sd", "psm_sd"), funs(round(.,0)))
@

<<label=usecase1, eval = TRUE, fig = TRUE, width = 6, height = 6, echo = FALSE, include = FALSE>>=
rawDiag:::.technote_application_figure_1(WU163763)
@

<<label=usecase2, eval = TRUE, fig = TRUE, width = 6, height = 6, echo = FALSE, include = FALSE>>=
rawDiag:::.technote_application_figure_2(WU163763) 
@

<<label=usecase3, eval = TRUE, fig = TRUE, width = 6, height = 4, echo = FALSE, include = FALSE>>=
rawDiag:::.technote_application_figure_3(searchResults)
@

<<label=usecase4, eval = TRUE, fig = TRUE, width = 6, height = 4, echo = FALSE, include = FALSE>>=
rawDiag:::.technote_application_figure_4(WU163763, searchResults)
@

<<label=usecase5, eval = TRUE, fig = TRUE, width = 6, height = 4, echo = FALSE, include = FALSE>>=
rawDiag:::.technote_application_figure_5(WU163763)
@


\begin{figure}[H]
\centering
 \includegraphics[width=0.49\columnwidth]{rawDiag-usecase1}
 \includegraphics[width=0.49\columnwidth]{rawDiag-usecase2}
 \includegraphics[width=0.32\columnwidth]{rawDiag-usecase3}
 \includegraphics[width=0.32\columnwidth]{rawDiag-usecase4}
 \includegraphics[width=0.32\columnwidth]{rawDiag-usecase5}
\caption{\textbf{A)}~Moving average of the scan speed of triplicate measurements of "Top18" (blue), "Top36" (green) and "Top72" (orange).
\textbf{B)} Number of MS2 scans for each scan cycle for "Top18" (blue), "Top36" (green) and "Top72" (orange).
\textbf{C)} Number of Proteins (orange) and peptides (blue) for the different TopN settings (note: number of peptides is divided by 10 in this plot due to scaling reasons).
\textbf{D)} Number of PSM (blue) and MS2 scans (orange) for the different TopN settings.
\textbf{E)} Time spent on MS1 (blue) and MS2 (orange) for the different TopN settings. Time range for calculation is the elution phase of the peptides between 15-70 min.}
\label{figure:application}
\end{figure}

Interestingly, the number confident of peptide spectrum matches (PSM) is reaching a plateau phase in the "Top72" method 
compared with the "Top36" ("Top36" has a slightly hihger number of significat psm than "Top72"). One potential explanation for this finding can be the quality of the recorded spectra. Due to the fact that the "Top72" method is sampling the precursors in our sample to such a deep degree, the injection time to prepare the ion packages for many low abundant species might be too low. This low amount of ions for fragmentation can influence the quality of the resulting fragment spectrum and hence lead to a non assigned spectrum. Since we still acquire much more MS2 spectra compared to the "Top36" method this is not yet seen in the number of significant peptide and protein hits (more spectra in general lead to more peptide and protein assignments) but indicates a suboptimal usage of the instrument. This finding could lead directly to a furhter refinement circle of the method.
New methods could be designed where the number of MS2 scans is reduced and concomitant the injection time parameter for MS2 scans is increased. Care should be taken to keep the cycle time of the methods constant. These new designed methods together with the "Top72" method would then be reanalyzed and again the data can be visualized to check if a method is fullfilling the MS operators requrements or if new parameters need optimization. 


\subsection{Related work}
To our knowledge the only alternative tool that is able to extract and visualize metadata from raw files on single scan granularity  is rawMeat (Vast Scientific). Unfortunately, it was discontinued years ago and built on the outdated MSFileReader libraries from Thermo Fisher Scientific (MS Windows only). This means that it does not fully support the latest generation of qOrbi instruments. Other loosely related tools \cite{pmid28802010, pmid25798920, pmid29324744, pmid27700092} are tailored towards longitudinal data recording and serve the purpose of quality control\cite{SIMPATIQCO} (monitoring of instrument performance) rather than method optimization. 


\section{Conclusion}
In this manuscript, we present \rawDiag~an R package to visualize characteristics of LC-MS measurements. Through its diagnostic plots, \rawDiag~supports scientists during empirical method optimization by providing a rational base for choosing appropriate data acquisition parameters. The software is fast, interactive and easy to operate through an R shiny GUI application, even for users without prior R knowledge. More advanced users can fully customize the appearance of the visualizations by executing their own code from the R command line. This also enables \rawDiag~to be customized and implemented into more complex environments, e.g., data analysis pipelines embedded into a LIMS systems. In its current implementation, the software is tailored towards the Thermo Fisher Scientific raw file format, but its architecture allows easy adaptation towards other MS data formats. An interesting showcase would be the novel Bruker tdf 2.0 format (introduced for the timsTOF Pro), where scan data is stored in an SQLite databse directly accessible to R. As future work, \rawDiag~could be extended to link additinal metadata not stored in the raw files. One example could be scan metadata generated by database search engienes (e.g., peptide sequences, identification scores, ...). Such additinal data would allow the visualization of assignment rates and score distributions across injections. By linking primary and derived metadata, the nature of \rawDiag~could be changed from a simple diagnostic tool to an application that allows big data analysis similar to MassIVE (\url{https://massive.ucsd.edu}, March 2018) but with the possibility to bypassing the currently necessary conversion to open data formats like mzML.


\section{Funding Sources}
The work has been supported by ETH Zurich and University of Zurich.

\begin{acknowledgement}
The authors thank Jim Shofstahl for his support regarding the
{\em New Thermo Fisher RawFileReader} library.
We thank Sven Brehmer from Bruker Daltonics for the discussions of timsTOF file
format. We thank Lilly van de Venn for the package logo design.
Two anonymous reviewers and editor Susan T. Weintraub have made numerous suggestions
and recommendations leading to a much improved presentation of the work.
We thank Jay Tracy and our colleagues at the Functional Genomics Center Zurich for proofreading our manuscript, the Swiss
Federal Institute of Technology Zurich and the University of Zurich for the
support of our work.
\end{acknowledgement}

\begin{suppinfo}
The package vignette \citep{rawDiag} as well as the R package itself,
a Dockerfile which builds the entire architecture from scratch is accessible through a git repository under the following URL: \url{https://github.com/fgcz/rawDiag}.
An automatic build of the provided docker recipe is visible through \url{https://hub.docker.com/r/cpanse/rawdiag/}.
The data used in section \ref{section:application} are available on the MassIVE
\url{ftp://massive.ucsd.edu/MSV000082389/raw/rawDiag/raw/}, through the
lab information managment system bfabric~\cite{bfabric} \url{https://fgcz-bfabric.uzh.ch} Sample ID 174020, or
as data set of the package as \texttt{WU163763}.
A demo system including all data shown in this manuscript is available through
\url{http://fgcz-ms-shiny.uzh.ch:8080/rawDiag-demo/}.
\end{suppinfo}

\bibliography{rawDiag}
\end{document}
